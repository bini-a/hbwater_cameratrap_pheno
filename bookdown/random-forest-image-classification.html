<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Random Forest Image Classification | 04-machinelearning.knit</title>
  <meta name="description" content="" />
  <meta name="generator" content="bookdown 0.27 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Random Forest Image Classification | 04-machinelearning.knit" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Random Forest Image Classification | 04-machinelearning.knit" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  


<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path=""><a href="#random-forest-image-classification"><i class="fa fa-check"></i><b>1</b> Random Forest Image Classification</a>
<ul>
<li class="chapter" data-level="1.1" data-path=""><a href="#introduction-to-random-forest"><i class="fa fa-check"></i><b>1.1</b> Introduction to Random Forest</a></li>
<li class="chapter" data-level="1.2" data-path=""><a href="#using-the-script"><i class="fa fa-check"></i><b>1.2</b> Using the Script</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path=""><a href="#data-preparation"><i class="fa fa-check"></i><b>1.2.1</b> Data Preparation</a></li>
<li class="chapter" data-level="1.2.2" data-path=""><a href="#hyperparameter-tuning"><i class="fa fa-check"></i><b>1.2.2</b> Hyperparameter Tuning</a></li>
<li class="chapter" data-level="1.2.3" data-path=""><a href="#training-random-forest-model"><i class="fa fa-check"></i><b>1.2.3</b> Training Random Forest Model</a></li>
<li class="chapter" data-level="1.2.4" data-path=""><a href="#generating-reclassified-images"><i class="fa fa-check"></i><b>1.2.4</b> Generating Reclassified Images</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path=""><a href="#future-improvements"><i class="fa fa-check"></i><b>1.3</b> Future Improvements</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:title:end-->
<!--bookdown:title:start-->
<div id="random-forest-image-classification" class="section level1 hasAnchor" number="1">
<h1><span class="header-section-number">Chapter 1</span> Random Forest Image Classification<a href="#random-forest-image-classification" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>The last step in the data pipeline is to run a random forest model to classify images.
The script for running the machine learning model is <code>ml_model_final.ipynb</code> (hosted in Jupyter Notebook).</p>
<div id="introduction-to-random-forest" class="section level2 hasAnchor" number="1.1">
<h2><span class="header-section-number">1.1</span> Introduction to Random Forest<a href="#introduction-to-random-forest" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Our machine learning model used a random forest model, which is a type of ensemble learning method for classification. It works by taking a set number of decision trees all operating independently, and outputting the result selected by the largest number of trees.</p>
<p>We chose a RF model for machine learning because it typically does a better job of not <strong>overfitting</strong>. This was important for our study at Hubbard Brook, because our images contained a large class imbalance. See the image below for an example class distribution (opaque snow and dark open water were far more prevalent than riffles/green leaves at this location).</p>
<p><img src="imgs/pixelclasses.png" width="200%" /></p>
<p>Other benefits of the random forest model are that it easily provides variable/feature importance, which is useful when evaluating the moderl’s performance. Additionally, we have tried an unsupervised learning approach with a convolutional neural network (CNN), which did not perform well on images with both leaves and ice.</p>
</div>
<div id="using-the-script" class="section level2 hasAnchor" number="1.2">
<h2><span class="header-section-number">1.2</span> Using the Script<a href="#using-the-script" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="data-preparation" class="section level3 hasAnchor" number="1.2.1">
<h3><span class="header-section-number">1.2.1</span> Data Preparation<a href="#data-preparation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>First, load in all necessary packages.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split, RandomizedSearchCV,GridSearchCV</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report,confusion_matrix, accuracy_score</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> ConfusionMatrixDisplay</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">&quot;ignore&quot;</span>)</span></code></pre></div>
<p>The first step is to wrangle the data so it can be fed into the model. Read in your <code>.csv</code> files and run all the code chunks</p>
<p>The below code chunk contains the functions for data wrangling which create data and temperature columns for the dataframe, as well as sampling from each class.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> wrangle_data(df):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&#39;&#39;&#39;</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Create date and temperature columns for dataframes</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co">    &#39;&#39;&#39;</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># remove duplicate RGB</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> df.drop_duplicates()</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&quot;date&quot;</span>] <span class="op">=</span> pd.to_datetime(df[<span class="st">&quot;date&quot;</span>])</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&quot;temperature&quot;</span>] <span class="op">=</span> df.temperature.<span class="bu">apply</span>(<span class="kw">lambda</span> a: <span class="bu">float</span>(a[:<span class="op">-</span><span class="dv">1</span>]) <span class="cf">if</span> <span class="bu">type</span>(a) <span class="op">!=</span> <span class="bu">float</span> <span class="cf">else</span> np.nan)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> pick_samples(df):</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">&#39;&#39;&#39;</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co">    pick samples from each class with defined max class size</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="co">    &#39;&#39;&#39;</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    sampled_df <span class="op">=</span> df.head(<span class="dv">1</span>)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    max_class_size <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> date <span class="kw">in</span> df.orig_name.unique():</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>        date_grouped <span class="op">=</span> df[df.orig_name<span class="op">==</span>date]</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>        nth <span class="op">=</span> <span class="bu">len</span>(date_grouped)<span class="op">//</span>max_class_size</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> nth<span class="op">==</span><span class="dv">0</span>:</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>            sampled_df <span class="op">=</span> pd.concat([sampled_df,date_grouped])</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>            curr_group <span class="op">=</span> date_grouped.iloc[::nth,:]</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>            sampled_df <span class="op">=</span> pd.concat([sampled_df,curr_group])</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    sampled_df.drop_duplicates(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sampled_df</span></code></pre></div>
<p>After the data wrangling is complete, the notebook first runs the model - the low accuracy will be corrected through the next step of hyperparameter tuning.</p>
</div>
<div id="hyperparameter-tuning" class="section level3 hasAnchor" number="1.2.2">
<h3><span class="header-section-number">1.2.2</span> Hyperparameter Tuning<a href="#hyperparameter-tuning" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Hyperparameter tuning is the process which helps select the optimal model architecture. For instance, one such question is: how many trees should I include in my random forest?</p>
<p>We used two tuning methods, grid search and random search.
- Grid search builds a model for each one of the possible hyperparameter values, and selects the model with the best results.
- Random search defines distributions for the hyperparameters, and not all values are tested - values tested are selected at random.</p>
</div>
<div id="training-random-forest-model" class="section level3 hasAnchor" number="1.2.3">
<h3><span class="header-section-number">1.2.3</span> Training Random Forest Model<a href="#training-random-forest-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Advance to the section titled <strong>Train Random Forest Model</strong>. The first section creates the functions for training the model. It splits the dataset into training and test sets and then fits the model. The second function plots the confusion matrix displaying the model’s accuracy.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> split_fit_basic_report(df):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Split dataset into training and test, fit model using default RCF parameters</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co">    return model, prediction, feature_importances, X_train, X_test, y_train, y_test</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> df.drop(<span class="st">&#39;class&#39;</span>,axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> df[<span class="st">&#39;class&#39;</span>] </span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.30</span>, random_state<span class="op">=</span><span class="dv">1</span>, stratify<span class="op">=</span>y)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    rfc <span class="op">=</span> RandomForestClassifier(random_state <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    rfc.fit(X_train, y_train)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># predict on test data</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    rfc_pred <span class="op">=</span> rfc.predict(X_test)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(classification_report(y_test,rfc_pred))</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    feature_val <span class="op">=</span> pd.DataFrame(rfc.feature_importances_, index <span class="op">=</span> X_train.columns)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(feature_val.sort_values(<span class="dv">0</span>, ascending<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> rfc, rfc_pred,feature_val,  X_train, X_test, y_train, y_test</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_cm(y_test, rfc_pred):</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="co">    plot confusion matrix of model predictions</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>    p,ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">30</span>, <span class="dv">20</span>))</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>    ConfusionMatrixDisplay.from_predictions(y_test, rfc_pred, ax<span class="op">=</span>ax, colorbar<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code></pre></div>
<p>Run the subsequent code chunks to use grid search CV and random search CV to select the best estimators for the model. After this is done, we then test the model on unseen data which is not used for training/testing.</p>
</div>
<div id="generating-reclassified-images" class="section level3 hasAnchor" number="1.2.4">
<h3><span class="header-section-number">1.2.4</span> Generating Reclassified Images<a href="#generating-reclassified-images" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The last section in the workbook is how we visualize the results of our model. We use the model to generate a reclassified image containing pixel predictions for the region of interest. The first section is a dictionary mapping each attribute to the color it will appear in the image, which can be tweaked based on personal preference.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>li <span class="op">=</span> [<span class="st">&#39;x&#39;</span>, <span class="st">&#39;y&#39;</span>, <span class="st">&#39;R&#39;</span>, <span class="st">&#39;G&#39;</span>, <span class="st">&#39;B&#39;</span>, <span class="st">&#39;temperature&#39;</span>, <span class="st">&#39;year&#39;</span>, <span class="st">&#39;week&#39;</span>, <span class="st">&#39;month&#39;</span>,</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>       <span class="st">&#39;season_autumn&#39;</span>, <span class="st">&#39;season_spring&#39;</span>, <span class="st">&#39;season_winter&#39;</span>]</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> display_predict_img(<span class="bu">file</span>):</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    img<span class="op">=</span> np.asarray(Image.<span class="bu">open</span>(<span class="st">&quot;invert_&quot;</span><span class="op">+</span><span class="bu">file</span>))</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    img_cp <span class="op">=</span> img.copy()</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    ind <span class="op">=</span>np.where((img[:,:,<span class="dv">0</span>]<span class="op">!=</span><span class="dv">0</span>) <span class="op">&amp;</span> (img[:,:,<span class="dv">1</span>]<span class="op">!=</span><span class="dv">0</span>) <span class="op">&amp;</span> (img[:,:,<span class="dv">2</span>]<span class="op">!=</span><span class="dv">0</span>))</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    y_vals <span class="op">=</span> ind[<span class="dv">0</span>]</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    x_vals <span class="op">=</span> ind[<span class="dv">1</span>]</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    _<span class="op">=</span> img[y_vals,x_vals,:]</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    r_vals, g_vals, b_vals <span class="op">=</span> _[:,<span class="dv">0</span>], _[:,<span class="dv">1</span>], _[:,<span class="dv">2</span>]</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    fl <span class="op">=</span> merged[merged.orig_name<span class="op">==</span><span class="bu">file</span>][li].head(<span class="dv">1</span>)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    point <span class="op">=</span> pd.DataFrame({<span class="st">&#39;x&#39;</span>: x_vals,</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>     <span class="st">&#39;y&#39;</span>: y_vals,</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>     <span class="st">&#39;R&#39;</span>: r_vals,</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>     <span class="st">&#39;G&#39;</span>: g_vals,</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>     <span class="st">&#39;B&#39;</span>: b_vals,</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    point[<span class="st">&#39;temperature&#39;</span>]<span class="op">=</span> fl.temperature.values[<span class="dv">0</span>]</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    point[<span class="st">&#39;year&#39;</span>]<span class="op">=</span> fl.year.values[<span class="dv">0</span>]</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    point[<span class="st">&#39;week&#39;</span>]<span class="op">=</span> fl.week.values[<span class="dv">0</span>]</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>    point[<span class="st">&#39;month&#39;</span>]<span class="op">=</span> fl.month.values[<span class="dv">0</span>]</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>    point[<span class="st">&#39;season_autumn&#39;</span>]<span class="op">=</span> fl.season_autumn.values[<span class="dv">0</span>]</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    point[<span class="st">&#39;season_spring&#39;</span>]<span class="op">=</span> fl.season_spring.values[<span class="dv">0</span>]</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>    point[<span class="st">&#39;season_winter&#39;</span>]<span class="op">=</span> fl.season_winter.values[<span class="dv">0</span>]</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>    pr <span class="op">=</span> model.predict(point)</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>    point[<span class="st">&quot;pred_class&quot;</span>] <span class="op">=</span> pr</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> apply_change(row):</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> row[<span class="st">&quot;pred_class&quot;</span>]</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>        newR, newG, newB<span class="op">=</span>colors[class_rgb[pred]]</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>        img_cp[row.y,row.x,:] <span class="op">=</span> [newR, newG,newB]</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>    point.<span class="bu">apply</span>(<span class="kw">lambda</span> x: apply_change(x), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>    f, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">0</span>].imshow(img)</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">1</span>].imshow(img_cp)</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>    f.set_figheight(<span class="dv">15</span>)</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>    f.set_figwidth(<span class="dv">15</span>)</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> img, img_cp, point</span></code></pre></div>
<p>This function uses the model output to re-map the image. Below are some outputs generated by the model. The first image shows the model does an excellent job distinguishing between snow and water, practically mapping out the original image exactly. The second image is a bit more ambiguous with a mixture of submerged leaves, ice, and rock, but the model is still able to predict them fairly accurately.</p>
<p><img src="imgs/snowice_output.png" width="200%" /><img src="imgs/output2.png" width="200%" /></p>
</div>
</div>
<div id="future-improvements" class="section level2 hasAnchor" number="1.3">
<h2><span class="header-section-number">1.3</span> Future Improvements<a href="#future-improvements" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>While our model achieved a high accuracy and recall of 96% for our images, there are still areas for fine-tuning and improvement. For one, the model was occasionally less accurate when attempting to differentiate between water and leaves/rocks in the stream channel, as well as other classes less prevalent in the training set. This is the case in the image here:</p>
<p><img src="imgs/leafrock_output.png" width="200%" /></p>
<p>Thus, in the future, exposing the model to more training data with these classes can improve its accuracy. Additionally, the model can be expanded to differentiate between different types of ice, which can be of use to researchers studying ice jams - this is just one of many potential changes.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>


    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/henrysun9074/hbwater_cameratrap_pheno/edit/master/%s",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/henrysun9074/hbwater_cameratrap_pheno/blob/master/%s",
"text": null
},
"download": null,
"search": false,
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
